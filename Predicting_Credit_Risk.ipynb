{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed75774",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning: Predicting Credit Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3113ef",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a23c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6420174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77536, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "\n",
    "file_path = \"Resources/lending_data.csv\"\n",
    "\n",
    "lending_data = pd.read_csv(file_path)\n",
    "lending_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd1d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove loan_status from data set\n",
    "\n",
    "y = lending_data[\"loan_status\"]\n",
    "X = lending_data.drop(columns = \"loan_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39df52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af910fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data sets\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4979ec",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8a606",
   "metadata": {},
   "source": [
    "I predict that the Random Forest Classifier will perform better. The `borrower_income`, `debt_to_income`, and `total_debt` fields are all related to one another. An underlying assumption of the Logistic Regression is that the independent variables aren't correlated, and that doesn't seem to be true in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f50d34",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2440bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make logistic regressor\n",
    "\n",
    "log_res = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e632ed15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model on training set\n",
    "\n",
    "log_res.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81247f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy on the training set: 99.412%\n",
      "Logistic Regression accuracy on the test set: 99.417%\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "\n",
    "accuracy_lr_train = round((log_res.score(X_train_scaled, y_train)*100),3)\n",
    "accuracy_lr_test = round((log_res.score(X_test_scaled, y_test)*100),3)\n",
    "print(f'Logistic Regression accuracy on the training set: {accuracy_lr_train}%')\n",
    "print(f'Logistic Regression accuracy on the test set: {accuracy_lr_test}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e05b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18690,   102],\n",
       "       [   11,   581]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate effectiveness\n",
    "\n",
    "y_true_lr = y_test\n",
    "y_pred_lr = log_res.predict(X_test_scaled)\n",
    "\n",
    "confusion_matrix(y_true_lr, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc29afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 18690, False Positives: 102\n",
      "False Negatives: 11, True Positives: 581\n"
     ]
    }
   ],
   "source": [
    "tn_lr, fp_lr, fn_lr, tp_lr = confusion_matrix(y_true_lr, y_pred_lr).ravel()\n",
    "\n",
    "print(f'True Negatives: {tn_lr}, False Positives: {fp_lr}')\n",
    "print(f'False Negatives: {fn_lr}, True Positives: {tp_lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a8018b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Precision: 85.066%\n"
     ]
    }
   ],
   "source": [
    "precision_lr = round((tp_lr/(tp_lr+fp_lr))*100, 3)\n",
    "print(f'Logistic Regression Precision: {precision_lr}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0a7e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Sensitivity: 98.142%\n"
     ]
    }
   ],
   "source": [
    "sensitivity_lr = round((tp_lr/(tp_lr+fn_lr))*100, 3)\n",
    "print(f'Logistic Regression Sensitivity: {sensitivity_lr}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e53ff0",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19f571e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random forest classifier\n",
    "\n",
    "rand_forest = RandomForestClassifier(n_estimators=100, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a514d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model on training set\n",
    "\n",
    "rand_forest.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c326dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier accuracy on the training set: 99.718%\n",
      "Random Forest Classifier accuracy on the testing set: 99.175%\n"
     ]
    }
   ],
   "source": [
    "# Test model on testing set\n",
    "\n",
    "accuracy_rf_train = round((rand_forest.score(X_train_scaled, y_train)*100), 3)\n",
    "accuracy_rf_test = round((rand_forest.score(X_test_scaled, y_test)*100), 3)\n",
    "\n",
    "print(f'Random Forest Classifier accuracy on the training set: {accuracy_rf_train}%')\n",
    "print(f'Random Forest Classifier accuracy on the testing set: {accuracy_rf_test}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "241dba81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18694,    98],\n",
       "       [   62,   530]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate effectiveness\n",
    "\n",
    "y_true_rf = y_test\n",
    "y_pred_rf = rand_forest.predict(X_test_scaled)\n",
    "\n",
    "confusion_matrix(y_true_rf, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4f59276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 18694, False Positives: 98\n",
      "False Negatives: 62, True Positives: 530\n"
     ]
    }
   ],
   "source": [
    "tn_rf, fp_rf, fn_rf, tp_rf = confusion_matrix(y_true_rf, y_pred_rf).ravel()\n",
    "\n",
    "print(f'True Negatives: {tn_rf}, False Positives: {fp_rf}')\n",
    "print(f'False Negatives: {fn_rf}, True Positives: {tp_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "333b008f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 84.395%\n"
     ]
    }
   ],
   "source": [
    "precision_rf = round((tp_rf/(tp_rf+fp_rf))*100, 3)\n",
    "print(f'Random Forest Classifier Precision: {precision_rf}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "178a2471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Sensitivity: 89.527%\n"
     ]
    }
   ],
   "source": [
    "sensitivity_rf = round((tp_rf/(tp_rf+fn_rf))*100, 3)\n",
    "print(f'Random Forest Classifier Sensitivity: {sensitivity_rf}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d736c72",
   "metadata": {},
   "source": [
    "### Analysis and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6942cf64",
   "metadata": {},
   "source": [
    "In this comparison of logistic regression and random tree classification, I notice that the results are very similar between the two models, but the logistic regression does slightly better. The models are close to each other in their accuracy and precision, but the logistic regression is significantly more precise. I am a little surprised that the logistic regression did better, because I had concerns that the test variables were too reliant on each other, but I can see that the logistic regression wins out in spite of that.\n",
    "\n",
    "The logistic regression was also a lot faster than the random forest classifier, so if I were to approach a problem like this again, I would probably run a logistic regression first, to see how well it does on the data set. If it didn't perform well, I would move on to trying another method, such as a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a326753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 99.417%, Random Forest accuracy: 99.175%\n",
      "Logistic Regression precision: 85.066%, Random Forest precision: 84.395%\n",
      "Logistic Regression sensitivity: 98.142%, Random Forest sensitivity: 89.527%\n"
     ]
    }
   ],
   "source": [
    "# I have listed the accuracy, precision, and sensitivity measures for each method for quick reference\n",
    "\n",
    "print(f'Logistic Regression accuracy: {accuracy_lr_test}%, Random Forest accuracy: {accuracy_rf_test}%')\n",
    "print(f'Logistic Regression precision: {precision_lr}%, Random Forest precision: {precision_rf}%')\n",
    "print(f'Logistic Regression sensitivity: {sensitivity_lr}%, Random Forest sensitivity: {sensitivity_rf}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b407ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
